name: 'training spawner with single fixed hp set'

resources:
  conda_env: 'pytorch'
  wandb_project: 'umbreon'
  cluster: 'baobab'

logging:
  checkpoint_dir: 'data/checkpoints'
  log_dir: 'data/logs'
  record: false

parameters:
  # Generic
  task: 'train'
  algo: 'gail'
  cuda: false
  num_seeds: 5
  benchmark: 'mujoco'

  # Training
  save_frequency: 1000
  num_timesteps: 1e7
  eval_steps_per_iter: 10
  eval_frequency: 10

  # Model
  perception_stack: 'shallow_mlp'
  shared_value: false

  # Optimization
  p_lr: 2.5e-4
  v_lr: 2.5e-4
  with_scheduler: true
  clip_norm: 0.5

  # Algorithm
  rollout_len: 1024
  optim_epochs_per_iter: 3
  batch_size: 128
  gamma: 0.99
  gae_lambda: 0.95
  eps: 0.2
  baseline_scale: 0.5
  p_ent_reg_scale: 0.

  # Adversarial imitation
  d_lr: 1e-4
  state_only: false
  minimax_only: true
  d_ent_reg_scale: 0.001
  d_update_ratio: 1
  grad_pen: true
  fake_ls_type: '"none"'
  real_ls_type: '"none"'
  syn_rew_scale: 1.
  wrap_absorb: true

  # KYE
  kye_p_binning: false
  kye_p_regress: false
  kye_p_scale: 0.1
  kye_d_regress: false
  kye_d_scale: 0.1
  kye_mixing: true

  # PU
  use_purl: false
  purl_eta: 0.25
